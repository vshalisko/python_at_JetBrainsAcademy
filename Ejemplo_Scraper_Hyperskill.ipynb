{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT6YwCiUyje1HYNs/y2M40",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vshalisko/python_at_JetBrainsAcademy/blob/main/Ejemplo_Scraper_Hyperskill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YLoYsKsoy7Gr"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_22p-8hGbcFx",
        "outputId": "938ef36f-0a0a-49fe-ff7d-fab6efb65ba6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Url 0: https://icanhazdadjoke.com/j/R7UfaahVfFd\n",
        "* Url 1: https://www.nature.com/articles/d41586-023-00103-3"
      ],
      "metadata": {
        "id": "SBgXs4B2b2cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Input the URL:')\n",
        "url = str(input())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej87w4VV0svZ",
        "outputId": "532094e2-e580-4685-c834-5038d6b8dc94"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input the URL:\n",
            "https://www.nature.com/articles/d41586-023-00103-3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    response = requests.get(url,\n",
        "                            headers={'Accept': 'application/json',\n",
        "                                     'Accept-Language': 'en-US,en;q=0.5'})\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        if 'joke' in data:\n",
        "            print(data['joke'])\n",
        "        else:\n",
        "            print('Invalid resource!')\n",
        "    else:\n",
        "        print('Invalid resource!')\n",
        "except requests.exceptions.RequestException:\n",
        "    print('Invalid resource!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rQGAagB0pau",
        "outputId": "cef60567-cf1c-4f34-b0e0-f2e4d7af7423"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My dog used to chase people on a bike a lot. It got so bad I had to take his bike away.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'nature.com/articles/' in url:\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            title = soup.find('title').get_text() if soup.find('title') else 'N/A'\n",
        "            description_meta = soup.find('meta', {'name': 'description'})\n",
        "            description = description_meta['content'] if description_meta and 'content' in description_meta.attrs else 'N/A'\n",
        "            print({\"title\": title, \"description\": description})\n",
        "        else:\n",
        "            print('Invalid page!')\n",
        "    except requests.exceptions.RequestException:\n",
        "        print('Invalid page!')\n",
        "else:\n",
        "    print('Invalid page!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jckf_hJA2qPl",
        "outputId": "b4029f2e-b67b-48bc-ed66-8ae765c9b450"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input the URL:\n",
            " https://www.nature.com/articles/d41586-023-00103-3\n",
            "{'title': 'Night skies are brightening â€” and dimming the outlook for astronomy', 'description': 'Fewer stars are visible worldwide now than a decade ago, according to measurements by community scientists.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from http import HTTPStatus\n",
        "\n",
        "path = '/content/drive/MyDrive/Colab Data/'\n",
        "filename = 'source.html'\n",
        "path_filename = path + filename\n",
        "\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == HTTPStatus.OK:\n",
        "        with open(path + filename, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f'Content saved at {path_filename}.')\n",
        "    else:\n",
        "        print(f'The URL returned {response.status_code}!')\n",
        "except requests.exceptions.RequestException:\n",
        "    print('Invalid URL or network error.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCkrsJGE3_mB",
        "outputId": "09654c97-50b0-4ea7-e9ee-b0f8dc5490a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content saved at /content/drive/MyDrive/Colab Data/source.html.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c26184e5"
      },
      "source": [
        "# Task\n",
        "Create a Python program that downloads the content of the URL \"https://www.nature.com/nature/articles?sort=PubDate&year=2020&page=3\", parses it to find links to \"News\" articles, downloads each of those news articles, extracts the article body from the `<p>` tag with the attribute `{\"class\": \"article__teaser\"}`, formats the article title by replacing spaces with underscores and removing punctuation, and saves the extracted article body to a text file named after the formatted title."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2965bcd4"
      },
      "source": [
        "## Fetch and parse the main page\n",
        "\n",
        "### Subtask:\n",
        "Download the content of the provided nature.com URL and parse it using BeautifulSoup.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62ce98b8"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to define the URL and download its content using requests, then parse the content with BeautifulSoup if the request is successful.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42b2bb84"
      },
      "source": [
        "url = \"https://www.nature.com/nature/articles?sort=PubDate&year=2020&page=3\"\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    else:\n",
        "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5db46010"
      },
      "source": [
        "## Find news article links\n",
        "\n",
        "### Subtask:\n",
        "Iterate through the parsed content to find all `<article>` tags. Within each article tag, identify the article type from the `<span>` tag with the `data-test=\"article.type\"` attribute. If the type is \"News\", extract the link to the article content from the `<a>` tag with the `data-track-action=\"view article\"` attribute. Store these links.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b7ccca9"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the parsed content to find news article links based on the specified criteria.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9416ffc7",
        "outputId": "6e19b8c8-7905-46d1-ccd3-4e84616dbcd7"
      },
      "source": [
        "article_tags = soup.find_all('article')\n",
        "news_article_urls = []\n",
        "\n",
        "for article in article_tags:\n",
        "    article_type_tag = article.find('span', {'data-test': 'article.type'})\n",
        "    if article_type_tag and article_type_tag.get_text(strip=True) == 'News':\n",
        "        article_link_tag = article.find('a', {'data-track-action': 'view article'})\n",
        "        if article_link_tag and 'href' in article_link_tag.attrs:\n",
        "            news_article_urls.append(\"https://www.nature.com\" + article_link_tag['href'])\n",
        "\n",
        "print(f\"Found {len(news_article_urls)} news article URLs.\")\n",
        "print(news_article_urls)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 news article URLs.\n",
            "['https://www.nature.com/articles/d41586-020-03621-6', 'https://www.nature.com/articles/d41586-020-03593-7', 'https://www.nature.com/articles/d41586-020-03561-1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06241783"
      },
      "source": [
        "## Fetch and parse each news article page\n",
        "\n",
        "### Subtask:\n",
        "For each news article link found in the previous step, download the content of that article's page and parse it using BeautifulSoup.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2b08b65"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the list of news article URLs, download the content of each page using requests, and parse it with BeautifulSoup, storing the parsed content along with the original URL.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "381f6b1c",
        "outputId": "d3b57c53-ac2c-45d9-9cbd-0a027c692b15"
      },
      "source": [
        "parsed_articles = []\n",
        "\n",
        "for url in news_article_urls:\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            parsed_articles.append({\"url\": url, \"soup\": soup})\n",
        "        else:\n",
        "            print(f\"Failed to retrieve the page {url}. Status code: {response.status_code}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred while processing {url}: {e}\")\n",
        "\n",
        "print(f\"Successfully parsed {len(parsed_articles)} news articles.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully parsed 3 news articles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaa6c5e8"
      },
      "source": [
        "## Extract article body\n",
        "\n",
        "### Subtask:\n",
        "From the parsed article page, find the `<p>` tag with the attribute `{\"class\": \"article__teaser\"}` and extract its text content.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85856709"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the parsed articles, find the article body tag, extract its text, and add it to the article dictionary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb027af6",
        "outputId": "cd6c4ad7-2b64-44bf-af45-e05ddd4286dc"
      },
      "source": [
        "for article in parsed_articles:\n",
        "    soup = article['soup']\n",
        "    body_tag = soup.find('p', {\"class\": \"article__teaser\"})\n",
        "    if body_tag:\n",
        "        article['body'] = body_tag.get_text(strip=True)\n",
        "    else:\n",
        "        article['body'] = 'Body not found'\n",
        "\n",
        "for article in parsed_articles:\n",
        "    print(f\"URL: {article['url']}\")\n",
        "    print(f\"Body: {article['body']}\")\n",
        "    print(\"-\" * 20)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL: https://www.nature.com/articles/d41586-020-03621-6\n",
            "Body: US president-elect Joe Biden has nominated Michael Regan, North Carolinaâ€™s top environmental regulator, to lead the countryâ€™s Environmental Protection Agency (EPA) â€” and scientists and environmentalists are optimistic.\n",
            "--------------------\n",
            "URL: https://www.nature.com/articles/d41586-020-03593-7\n",
            "Body: A week after granting an emergency-use authorization for the countryâ€™s first COVID-19 vaccine, US regulators have followed with a second: another RNA vaccine, this one made by Moderna of Cambridge, Massachusetts.\n",
            "--------------------\n",
            "URL: https://www.nature.com/articles/d41586-020-03561-1\n",
            "Body: Lightning is striking the Arctic many times more often than it did a decade ago, a study suggests â€” and the rate could soon double. The findings demonstrate yet another way Earthâ€™s climate could be changing as the planet warms, although not all researchers agree that the trend is real.\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1bbbe84"
      },
      "source": [
        "## Format article title and save content\n",
        "\n",
        "### Subtask:\n",
        "Get the article title, format it by replacing spaces with underscores and removing punctuation. Save the extracted article body text to a file named after the formatted title with a `.txt` extension.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87690c16"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the parsed articles, extract and format the title, and save the body to a file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "469b61f8",
        "outputId": "c8965977-a950-4b05-a62e-393895840710"
      },
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/Colab Data/'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(path, exist_ok=True)\n",
        "\n",
        "for article in parsed_articles:\n",
        "    soup = article['soup']\n",
        "    title_tag = soup.find('title')\n",
        "    title = title_tag.get_text() if title_tag else 'Untitled'\n",
        "    formatted_title = re.sub(r'[^\\w\\s-]', '', title).replace(' ', '_')\n",
        "    filename = f\"{formatted_title}.txt\"\n",
        "    filepath = os.path.join(path, filename)  # Use os.path.join for creating the full path\n",
        "    body = article['body']\n",
        "\n",
        "    try:\n",
        "        with open(filepath, 'wb') as f:\n",
        "            f.write(body.encode('utf-8'))\n",
        "        print(f\"Content saved to {filepath}\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error saving content to {filepath}: {e}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content saved to /content/drive/MyDrive/Colab Data/Bidens_pick_to_head_US_environment_agency_heartens_scientists.txt\n",
            "Content saved to /content/drive/MyDrive/Colab Data/Moderna_COVID_vaccine_becomes_second_to_get_US_authorization.txt\n",
            "Content saved to /content/drive/MyDrive/Colab Data/Is_lightning_striking_the_Arctic_more_than_ever_before.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7dc68ce"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The initial web page at \"https://www.nature.com/nature/articles?sort=PubDate&year=2020&page=3\" was successfully downloaded and parsed.\n",
        "*   Three news article URLs were identified from the main page.\n",
        "*   The content of all three identified news articles was successfully downloaded and parsed.\n",
        "*   For each news article, the body text was successfully extracted from the `<p>` tag with the class \"article__teaser\".\n",
        "*   The title of each article was extracted and formatted by replacing spaces with underscores and removing punctuation.\n",
        "*   The extracted article body of each news article was saved to a text file named after the formatted article title.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Consider adding error handling or logging for articles where the body tag is not found.\n",
        "*   The process could be extended to extract more information from each article page, such as author, publication date, or other sections of the article body.\n"
      ]
    }
  ]
}